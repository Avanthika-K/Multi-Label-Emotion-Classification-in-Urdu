{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**TFIDF VECTORIZAR,CLASSIFIER: MLKNN**"
      ],
      "metadata": {
        "id": "gVtXP6oKt0nN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SRALL9HpTjO",
        "outputId": "eea90987-cdcc-4356-cbec-f7a749231cfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-learn==0.24.1\n",
            "  Downloading scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24.1) (1.21.6)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.1 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.24.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n",
            "Mounted at /content/drive\n",
            "mount success\n"
          ]
        }
      ],
      "source": [
        "#needed installs\n",
        "!pip install scikit-learn==0.24.1\n",
        "!pip install scikit-multilearn\n",
        "\n",
        "#needed imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from skmultilearn.adapt import MLkNN\n",
        "from sklearn.metrics import hamming_loss, accuracy_score\n",
        "\n",
        "#mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print('mount success')\n",
        "\n",
        "#read from file\n",
        "aspects_df = pd.read_csv('/content/drive/Shareddrives/EMOThreat/train_set_taskA.csv')\n",
        "X = aspects_df[\"Sentences\"]\n",
        "y = np.asarray(aspects_df[aspects_df.columns[:7]])\n",
        "  \n",
        "# initializing TfidfVectorizer \n",
        "vetorizar = TfidfVectorizer(max_features=7000, max_df=0.85)\n",
        "# fitting the tf-idf on the given data\n",
        "vetorizar.fit(X)\n",
        "  \n",
        "# splitting the data to training and testing data set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
        "  \n",
        "# transforming the data\n",
        "X_train_tfidf = vetorizar.transform(X_train)\n",
        "X_test_tfidf = vetorizar.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "#using Multi-label kNN classifier  \n",
        "import time \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "start=time.time()\n",
        "\n",
        "mlknn_classifier = MLkNN(k=20)\n",
        "#print(X_train_tfidf.shape,\"\\n\\n\")\n",
        "mlknn_classifier.fit(X_train_tfidf, y_train)\n",
        "predicted = mlknn_classifier.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Hamming Lossing:\",hamming_loss(y_test, predicted))\n",
        "print(\"Accuracy Score:\",accuracy_score(y_test, predicted))\n",
        "print('Training Time Taken: ',round(time.time()-start,0),'seconds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdG8fLpBrYgT",
        "outputId": "e468bf25-6134-4a63-91bf-a2346b734c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hamming Lossing: 0.10476190476190476\n",
            "Accuracy Score: 0.5717948717948718\n",
            "Training Time Taken:  15.0 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import multilabel_confusion_matrix,classification_report\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "print(classification_report(y_test, predicted))\n",
        "print(multilabel_confusion_matrix(y_test, predicted))\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"ACC: \",accuracy_score(predicted,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0riZc_SHsUDi",
        "outputId": "61207ddf-9e9d-4a65-e625-fcc4b739a49c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.32      0.44        93\n",
            "           1       0.63      0.25      0.36        88\n",
            "           2       0.94      0.30      0.46        56\n",
            "           3       0.70      0.60      0.65       234\n",
            "           4       0.60      0.42      0.49       149\n",
            "           5       0.54      0.38      0.44        95\n",
            "           6       1.00      0.98      0.99       312\n",
            "\n",
            "   micro avg       0.79      0.60      0.68      1027\n",
            "   macro avg       0.73      0.46      0.55      1027\n",
            "weighted avg       0.77      0.60      0.66      1027\n",
            " samples avg       0.69      0.67      0.66      1027\n",
            "\n",
            "[[[675  12]\n",
            "  [ 63  30]]\n",
            "\n",
            " [[679  13]\n",
            "  [ 66  22]]\n",
            "\n",
            " [[723   1]\n",
            "  [ 39  17]]\n",
            "\n",
            " [[486  60]\n",
            "  [ 94 140]]\n",
            "\n",
            " [[589  42]\n",
            "  [ 87  62]]\n",
            "\n",
            " [[654  31]\n",
            "  [ 59  36]]\n",
            "\n",
            " [[468   0]\n",
            "  [  5 307]]]\n",
            "ACC:  0.5717948717948718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "aspects_df = pd.read_csv('/content/drive/Shareddrives/EMOThreat/test_set_taskA.csv')\n",
        "X = aspects_df[\"Sentences\"]\n",
        "xx=X\n",
        "vetorizar = TfidfVectorizer(max_features=7000, max_df=0.85)\n",
        "# fitting the tf-idf on the given data\n",
        "vetorizar.fit(X)\n",
        "X = vetorizar.transform(X)\n",
        "#knn_predictions = knn_classifier.predict(X)\n",
        "#dnn_predictions=dnn_classifier.predict(X)\n",
        "#rf_predictions=rf_classifier.predict(X)\n",
        "mlknn=mlknn_classifier.predict(X)\n",
        "csv = pd.DataFrame(mlknn.toarray(),columns=[\"anger\",\"disgust\",\"fear\",\"sadness\",\"surprise\",\"happiness\",\"neutral\"])\n",
        "csv.insert(7,\"Sentences\",aspects_df[\"Sentences\"],True)\n",
        "csv.to_csv(\"pred_tfidf_mlknn.csv\", index=False)"
      ],
      "metadata": {
        "id": "6daWn1WZ0mKI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}